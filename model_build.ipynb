{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xTlhrLJBu-GB"},"outputs":[],"source":["! pip install mecab-python3 unidic-lite\n","import MeCab\n","import numpy as np\n","import pandas as p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUFnbNJLvM6X"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLYcDR-uvVYt"},"outputs":[],"source":["from matplotlib.projections.geo import Circle\n","df = pd.read_csv('/content/drive/Shareddrives/FY22_市場開発部IS_学生作業用/train_data.csv')\n","print(df)\n","\n","niju = df[df['Label']=='◎']\n","maru = df[df['Label']=='○']\n","sikaku = df[df['Label']=='□']\n","sankaku = df[df['Label']=='▲']\n","batu = df[df['Label']=='×']\n","print(len(niju))\n","print(len(maru))\n","print(len(sikaku))\n","print(len(sankaku))\n","print(len(batu))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMkxXdo2vvWv"},"outputs":[],"source":["sikaku_han_random = sikaku.sample(frac=0.5) # ランダムに半分を取り出し\n","sikakules2 = pd.concat([sikaku_han_random, df[df['Label'] != '□']]) # □が入っていないdfに上を連結"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1ckz49zv7wK"},"outputs":[],"source":["df_mae = df[df.index<249738] # 前半\n","df_ato = df[df.index>=249738] # 後半"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_C30qVtwKuO"},"outputs":[],"source":["# すべてのコメント取り出してtxtに吐き出す\n","tagger = MeCab.Tagger('-Owakati')\n","\n","f = open('/content/drive/MyDrive/all_comment.txt', 'w')\n","for comment in df[\"Comment\"]:\n","  comment = str(comment).replace(\"・\", \"\").strip()\n","  comment = tagger.parse(comment) # ここで既に分かち済み\n","  print(comment, end=\"\", file=f)\n","  # f.write(str(comment))\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hw3D8aRfwAHe"},"outputs":[],"source":["! pip install gensim\n","from gensim.models import word2vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUJVIKk_wIfL"},"outputs":[],"source":["# word2vecモデルの作成(再実行不要)\n","docs = word2vec.LineSentence(\"/content/drive/MyDrive/all_comment.txt\")\n","model = word2vec.Word2Vec(docs, size=100, min_count=5, window=5, iter=3)\n","model.save(\"/content/drive/MyDrive/data_based.model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_53umipV1rv_"},"outputs":[],"source":["# 特定ワードに近い単語10個を出力\n","result = model.most_similar(positive=\"景気\", topn=10)\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIcf5RjC177h"},"outputs":[],"source":["tagger=MeCab.Tagger() # 上で記載済みだが念のため\n","data_based_model = word2vec.Word2Vec.load(\"/content/drive/MyDrive/data_based.model\") # データから作成したモデルを読み込み\n","# general_model = word2vec.Word2Vec.load(\"/content/drive/MyDrive/general.model\") # 汎用モデルを読み込み\n","\n","hukushi_dic = {'特に':0.5, 'やや':-0.25, '少し':-0.25, 'あまり':-0.25, 'まだ':-0.25, 'かなり':0.5, '依然':0, '全く':-0.75, 'なかなか':-0.25, 'しばらく':-0.25, '更に':0.25, 'ほぼ':0, 'まだまだ':-0.25, 'ますます':0.25, 'どう':0, 'そう':1, '大変':0.5, 'よく':0.5, 'より':0.5, '余り':-0.25} # 副詞リスト\n","# ↓改変版\n","# hukushi_dic = {'特に':0.5, 'やや':-0.25, '少し':-0.25, 'あまり':-0.5, 'まだ':-0.25, 'かなり':0.75, '依然':0, '全く':-0.75, 'なかなか':-0.5, 'しばらく':-0.25, '更に':0.25, 'ほぼ':0, 'まだまだ':-0.25, 'ますます':0.5, 'どう':0, 'そう':0, '大変':0.5, 'よく':0.5, 'より':0.5, '余り':-0.25} # 副詞リスト\n","hukushilist = list(hukushi_dic.keys())\n","jodoshi_dic = {'ない':-1, 'ず':-1, 'なく':-1, 'なかっ':-1, 'なけれ':-1, 'ざる':-1} # 助動詞リスト\n","# jodoshi_dic = {} # 助動詞リスト\n","\n","jodoshi_list = list(jodoshi_dic.keys())\n","n = 100 # ベクトルの次元\n","\n","# ランダムなしのコメント→ベクトル関数\n","def comment_to_vec(text):\n","  adv = 0 # 副詞カウンター\n","  h_num = 0 # 特定副詞のレバレッジ\n","  j_num = 0 # 特定助動詞のレバレッジ\n","  vec = np.zeros(n, dtype=np.float64) # dtypeは仮にfloat64に設定\n","  node = tagger.parseToNode(text).next # BOS/EOS部分を削除するために1つずらし\n","  \n","  while node.next: # 同様に一つずらし\n","    word = node.surface\n","    hinshi = node.feature.split(\",\")[0]\n","    try:\n","      node_vec = data_based_model[word]\n","    except KeyError:\n","      # node_vec = general_model[word] # 汎用モデルを使うことがあれば\n","      node_vec = np.zeros(n)\n","    \n","    # print(word, hinshi, node_vec)\n","    \n","    if hinshi == \"名詞\":\n","      vec += node_vec\n","\n","    elif hinshi == \"動詞\":\n","      if adv == 1: \n","        node_vec = node_vec * (1+h_num) # 副詞のレバレッジを乗算\n","        adv = 0\n","      if node.next.feature.split(\",\")[0] == \"助動詞\" and node.next.surface in jodoshi_list:\n","        j_num = jodoshi_dic[node.next.surface]\n","        node_vec = node_vec * j_num # 助動詞のレバレッジを乗算\n","        \n","      vec += node_vec\n","        \n","    elif hinshi == \"形容詞\":\n","      if adv == 1:\n","        node_vec = node_vec * (1+h_num) # 副詞のレバレッジを乗算\n","        adv = 0\n","        \n","      vec += node_vec\n","\n","    elif hinshi == \"副詞\":\n","      if word in hukushilist:\n","        h_num = hukushi_dic[word]\n","        adv = 1\n","      \n","      \n","    node = node.next\n","    \n","      \n","  return vec # 出力はdtype=float64のn次元ベクトル\n","\n","    \n","\n","\n","print(comment_to_vec(\"私は体操をする。\"))\n","print(comment_to_vec(\"私は特に体操をする。\"))\n","print(comment_to_vec(\"私は体操をした。\"))\n","print(comment_to_vec(\"私は体操をしなかった。\"))\n","\n","print(list(comment_to_vec(\"私は体操をした。\")))\n","print(type(list(comment_to_vec(\"私は体操をした。\"))))\n","print(len(list(comment_to_vec(\"私は体操をした。\"))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kzeHlpB2KHC"},"outputs":[],"source":["tagger=MeCab.Tagger() # 上で記載済みだが念のため\n","data_based_model = word2vec.Word2Vec.load(\"/content/drive/MyDrive/data_based.model\") # データから作成したモデルを読み込み\n","# general_model = word2vec.Word2Vec.load(\"/content/drive/MyDrive/general.model\") # 汎用モデルを読み込み\n","\n","hukushi_dic = {'特に':0.5, 'やや':-0.25, '少し':-0.25, 'あまり':-0.25, 'まだ':-0.25, 'かなり':0.5, '依然':0, '全く':-0.75, 'なかなか':-0.25, 'しばらく':-0.25, '更に':0.25, 'ほぼ':0, 'まだまだ':-0.25, 'ますます':0.25, 'どう':0, 'そう':1, '大変':0.5, 'よく':0.5, 'より':0.5, '余り':-0.25} # 副詞リスト\n","# ↓改変版\n","# hukushi_dic = {'特に':0.5, 'やや':-0.25, '少し':-0.25, 'あまり':-0.5, 'まだ':-0.25, 'かなり':0.75, '依然':0, '全く':-0.75, 'なかなか':-0.5, 'しばらく':-0.25, '更に':0.25, 'ほぼ':0, 'まだまだ':-0.25, 'ますます':0.5, 'どう':0, 'そう':0, '大変':0.5, 'よく':0.5, 'より':0.5, '余り':-0.25} # 副詞リスト\n","hukushilist = list(hukushi_dic.keys())\n","jodoshi_dic = {'ない':-1, 'ず':-1, 'なく':-1, 'なかっ':-1, 'なけれ':-1, 'ざる':-1} # 助動詞リスト\n","# jodoshi_dic = {} # 助動詞リスト\n","\n","jodoshi_list = list(jodoshi_dic.keys())\n","n = 100 # ベクトルの次元\n","\n","# ランダムありのコメント→ベクトル関数\n","def comment_to_vec_r(text):\n","  adv = 0 # 副詞カウンター\n","  h_num = 0 # 特定副詞のレバレッジ\n","  j_num = 0 # 特定助動詞のレバレッジ\n","  vec = np.zeros(n, dtype=np.float64) # dtypeは仮にfloat64に設定\n","  node = tagger.parseToNode(text).next # BOS/EOS部分を削除するために1つずらし\n","  \n","  while node.next: # 同様に一つずらし\n","    word = node.surface\n","    hinshi = node.feature.split(\",\")[0]\n","    rand = (1.05-0.95) * (np.random.rand()) + 0.95\n","    try:\n","      node_vec = (data_based_model[word]) * rand\n","    except KeyError:\n","      # node_vec = general_model[word] # 汎用モデルを使うことがあれば\n","      node_vec = np.zeros(n)\n","    \n","    # print(word, hinshi, node_vec)\n","    \n","    if hinshi == \"名詞\":\n","      vec += node_vec\n","\n","    elif hinshi == \"動詞\":\n","      if adv == 1: \n","        node_vec = node_vec * (1+h_num) # 副詞のレバレッジを乗算\n","        adv = 0\n","      if node.next.feature.split(\",\")[0] == \"助動詞\" and node.next.surface in jodoshi_list:\n","        j_num = jodoshi_dic[node.next.surface]\n","        node_vec = node_vec * j_num # 助動詞のレバレッジを乗算\n","        \n","      vec += node_vec\n","        \n","    elif hinshi == \"形容詞\":\n","      if adv == 1:\n","        node_vec = node_vec * (1+h_num) # 副詞のレバレッジを乗算\n","        adv = 0\n","        \n","      vec += node_vec\n","\n","    elif hinshi == \"副詞\":\n","      if word in hukushilist:\n","        h_num = hukushi_dic[word]\n","        adv = 1\n","      \n","      \n","    node = node.next\n","    \n","      \n","  return vec # 出力はdtype=float64のn次元ベクトル"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAWZIpZU2XDZ"},"outputs":[],"source":["# データセット作成(train)→csv出力\n","df = pd.read_csv('/content/drive/shareddrives/fy22_市場開発部is_学生作業用/train_data.csv')\n","df = df[['label', 'comment']]\n","print(df)\n","result_list = []\n","\n","for data in zip(df['label'], df['comment']):\n","  result = []\n","  label_num = 0\n","  if data[0] == '◎':\n","    label_num = 1.0\n","  elif data[0] == '○':\n","    label_num = 0.5\n","  elif data[0] == '□':\n","    label_num = 0\n","  elif data[0] == '▲':\n","    label_num = -0.5\n","  elif data[0] == '×':\n","    label_num = -1.0\n","  result.append(label_num)\n","  comment_vec = list(comment_to_vec(str(data[1]))) # n次元の固有ベクトルをリストで出力 水増しデータ作る場合はcomment_to_vec_rを使用\n","  result += comment_vec\n","  result_list.append(result)\n","  # print(result)\n","\n","result_df = pd.dataframe(result_list) # result_listをdataframeに変換\n","\n","result_df.to_csv(\"/content/drive/mydrive/train_data_set1.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ib1pmIbU2pa9"},"outputs":[],"source":["# データセット作成(test)→csv出力\n","df = pd.read_csv('/content/drive/Shareddrives/FY22_市場開発部IS_学生作業用/test_data.csv')\n","df = df[['Label', 'Comment']]\n","print(df)\n","result_list = []\n","\n","for data in zip(df['Label'], df['Comment']):\n","  result = []\n","  label_num = 0\n","  if data[0] == '◎':\n","    label_num = 1.0\n","  elif data[0] == '○':\n","    label_num = 0.5\n","  elif data[0] == '□':\n","    label_num = 0\n","  elif data[0] == '▲':\n","    label_num = -0.5\n","  elif data[0] == '×':\n","    label_num = -1.0\n","  result.append(label_num)\n","  comment_vec = list(comment_to_vec(str(data[1]))) # n次元の固有ベクトルをリストで出力\n","  result += comment_vec\n","  result_list.append(result)\n","  # print(result)\n","\n","result_df = pd.DataFrame(result_list) # result_listをdataframeに変換\n","\n","result_df.to_csv('/content/drive/MyDrive/test_data_set1.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hABHQS8k6lgH"},"outputs":[],"source":["!pip install keras \n","!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkAqH_qf66F0"},"outputs":[],"source":["import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.models import load_model\n","\n","from IPython.display import set_matplotlib_formats\n","set_matplotlib_formats('retina')\n","\n","# csv読み込む場合のやつ\n","# 教師データ取得\n","train_data = pd.read_csv('/content/drive/Shareddrives/FY22_市場開発部IS_学生作業用/train_data_set1.csv', index_col=0)\n","# print(train_data)\n","x_train = train_data.iloc[:, 1:101]\n","y_train = train_data['0']\n","# print(x_train)\n","# print(y_train)\n","\n","# テストデータ取得\n","test_data = pd.read_csv('/content/drive/Shareddrives/FY22_市場開発部IS_学生作業用//test_data_set1.csv', index_col=0)\n","# print(test_data)\n","x_test = test_data.iloc[:, 1:101]\n","y_test = test_data['0']\n","\n","# dataframeから直接読むのやつ\n","# train_data = pd.concat([train_result_df, train_result_df_r]) # 水増しデータをくっつける場合\n","# train_data = train_result_d # 通常時\n","# x_train = train_data.iloc[:, 1:101]\n","# y_train = train_data[0]\n","# print(train_data)\n","# print(x_train)\n","# print(y_train)\n","\n","# test_data = test_result_df\n","# x_test = test_data.iloc[:, 1:101]\n","# y_test = test_data[0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCc2O-xx756p"},"outputs":[],"source":["#ニューラルネットワーク\n","#中間層のニューロン数\n","\n","model = Sequential()\n","\n","#活性化関数\n","model.add(Dense(64, activation='swish', input_dim=100))\n","model.add(Dense(32, activation='swish'))\n","model.add(Dense(64, activation='swish',))\n","model.add(Dense(1, activation='linear'))\n","\n","#最適化アルゴリズム\n","model.compile(optimizer='rmsprop',\n","          loss='mean_squared_error',\n","          metrics=['accuracy'])\n","\n","#モデルの学習\n","train_history = model.fit(x_train, y_train,\n","        batch_size=2048,\n","        epochs=20,\n","        verbose=1)\n","\n","#損失値関数のプロット\n","fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n","ax.plot(train_history.history['loss'])\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('loss')\n","ax.set_xlim(0, 20)\n","ax.set_ylim(-0.01, 0.5)\n","# plt.savefig('nn-regression-train-1.png', dpi=300, facecolor='white')\n","plt.show()\n","\n","#予測\n","y_pred = model.predict(x_test)\n","                       \n","#決定係数計算\n","\n","from sklearn.metrics import mean_squared_error, r2_score\n","#R2\n","r2=r2_score(y_test, y_pred)\n","\n","#RMSE\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","print(\"R2:\",r2,\"RMSE:\",rmse)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Og4Su_P8LCO"},"outputs":[],"source":["# 一番良いモデルのみ保存\n","model.save('/content/drive/MyDrive/models/best_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUu5clzI8h8T"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, r2_score\n","\n","# ニューラルネットワーク(ループ版)\n","\n","#中間層のニューロン数\n","# nn1 = 64\n","# nn2 = 32\n","model = Sequential()\n","#活性化関数\n","model.add(Dense(64, activation='swish', input_dim=100))\n","model.add(Dense(32, activation='swish'))\n","model.add(Dense(64, activation='swish',))\n","model.add(Dense(1, activation='linear'))\n","\n","#最適化アルゴリズム\n","model.compile(optimizer='rmsprop',\n","          loss='mean_squared_error',\n","          metrics=['accuracy'])\n","\n","def fit():\n","  train_history = model.fit(x_train, y_train,\n","          batch_size=2048,\n","          epochs=20,\n","          verbose=0)\n","  # 予測\n","  y_pred = model.predict(x_test)\n","  \n","  #R2\n","  r2=r2_score(y_test, y_pred)\n","  \n","  #RMSE\n","  # rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","  return r2\n","\n","output_list = []\n","max = 0.3227\n","\n","for s in range(10):\n","  r2 = fit() \n","  if r2 > max:\n","    max = r2\n","    model.save(f'/content/drive/MyDrive/models/model_{max}') # 良いモデルの保存(ファイル名はmode_決定係数)\n","  print(s, r2)\n","  output_list.append(r2)\n","  \n","mean = np.mean(output_list)\n","\n","print(f'\\naverage={mean}')\n","\n","print(f'\\nmax={max}')\n","\n","output_list.append(mean)\n","output = pd.DataFrame(output_list)\n","output.to_csv(\"/content/drive/MyDrive/result_sample2.csv\") # R^2の保存(最終行はR^2の平均値)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0oDnvPS9Sbm"},"outputs":[],"source":["# 既存モデル読み込み&実行\n","# exist_model = load_model('/content/drive/Shareddrives/FY22_市場開発部IS_学生作業用/good_model.hdf5')\n","exist_model = load_model('/content/drive/MyDrive/models/model_0.3226864519183694(swish, 64 32 64 16)')\n","y_pred = exist_model.predict(x_test)\n","r2=r2_score(y_test, y_pred)\n","print(r2)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPPOdkvIX686pBilZtNGQVk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
